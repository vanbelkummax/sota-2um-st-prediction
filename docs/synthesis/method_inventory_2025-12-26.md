# Method Inventory - Spatial Transcriptomics Prediction from H&E

**Date**: 2025-12-26
**Phase**: Month 1 Week 1 - Literature Discovery
**Status**: Initial inventory complete

---

## Overview

This document catalogs all methods discovered for predicting spatial transcriptomics from H&E histology images. Methods are categorized by type and prioritized based on:
1. Claims at 2Î¼m or subcellular resolution
2. Code availability and reproducibility
3. Novelty of approach
4. Publication venue and recency

**Total Methods Found**: 45+

**Last Update**: 2025-12-26 (Critical infrastructure + generative methods added)

**Status**: Week 1 complete with optimized execution order

---

## Critical Reality Check: What "2Î¼m" Actually Means

âš ï¸ **Important**: Visium HD is a grid of 2Ã—2 Î¼m barcoded squares, but **10X recommends starting at 8Ã—8 Î¼m bins**. When papers claim "2Î¼m," verify:
- (a) **Raw 2Î¼m bins** (extremely sparse, ~90% zeros)
- (b) **Cell-level** maps rendered onto pixels
- (c) **8Î¼m bins** (most common)

**Implication**: True 2Î¼m prediction requires:
1. **Binâ†’cell assignment** (cells overlap bins, bins overlap cells)
2. **Sparsity handling** (regression/MSE collapses to zeros)
3. **Generative heads** (diffusion/flow/discrete counts)

---

## Tier -1: Infrastructure (The Missing Piece)

### ENACT â­â­â­ CRITICAL - START HERE â­â­â­
- **Paper**: Bioinformatics 2025 (OUP Academic)
- **PMID**: TBD
- **GitHub**: https://github.com/Sanofi-Public/enact-pipeline âœ…
- **Why CRITICAL**: **First tissue-agnostic pipeline for Visium HD binâ†’cell assignment**
- **What It Does**:
  - Cell segmentation (StarDist)
  - Multiple bin-to-cell assignment strategies
  - Outputs AnnData format
- **The Problem It Solves**: At 2Î¼m, cells overlap bins and bins overlap cells - you need assignment logic BEFORE prediction
- **Priority**: **MUST RUN FIRST** - this defines your ground truth
- **User Insight**: "Binâ†’cell is part of the model, not preprocessing"
- **Status**: Production-ready pipeline, Python-based
- **Note**: Without this, you're not truly working at 2Î¼m resolution

---

## Tier 0: Bleeding Edge (2024-2025 SOTA Breakthroughs)

### Stem (ICLR 2025) â­ GENERATIVE BASELINE - START HERE FOR DIFFUSION
- **Paper**: ICLR 2025
- **GitHub**: https://github.com/SichenZhu/Stem âœ…
- **Key Innovation**: **Conditional Diffusion for ST Prediction**
- **Paradigm Shift**: Generative (not regression) - learns distribution of possible expressions for given morphology
- **Why Critical**: Handles "one-to-many" biological reality (same morphology â†’ multiple possible cell states)
- **Implementation**: Clean repo, HEST integration, runnable
- **Resolution**: 2Î¼m capable
- **Priority**: **HIGHEST for generative baseline** - cleanest diffusion implementation
- **User Recommendation**: "If you want fast proof you can win, run Stem first"
- **Borrowed From**: Generative AI / Latent Diffusion Models (Stable Diffusion, DALL-E)

### STFlow (ICML 2025) â­ SLIDE-LEVEL JOINT MODELING
- **Paper**: ICML 2025
- **GitHub**: https://github.com/Graph-and-Geometric-Learning/STFlow âœ…
- **Key Innovation**: **Whole-slide flow matching** - models joint distribution across entire slide
- **Paradigm**: Spots are NOT independent - captures cell-cell interactions
- **Why Critical**: "If your thesis is 'slide-level structure matters', run STFlow"
- **Resolution**: Whole-slide scale
- **Priority**: **HIGH** - addresses spatial dependence explicitly
- **User Recommendation**: Alternative to Stem if slide-level structure is key hypothesis
- **Borrowed From**: Flow matching / Normalizing flows

### GenAR (Late 2025) â­ DISCRETE COUNT GENERATION
- **Paper**: OpenReview 2025
- **GitHub**: https://github.com/oyjr/genar âœ… (verify)
- **Key Innovation**: **Multi-scale autoregressive discrete count generation**
- **Why Critical**: Treats outputs as **discrete tokens/counts** (not continuous)
- **Addresses**: "Counts aren't continuous" - raw 2Î¼m bins are integer counts
- **Priority**: **HIGH** - direct counter to sparsity/zero-inflation
- **User Recommendation**: "Put GenAR on your radar specifically for discrete counts"
- **Note**: DeepSpot2Cell uses MSE (easy to beat with better likelihood/discrete head)
- **Borrowed From**: Autoregressive language models (GPT-style)

### PixNet (2025) - DENSE CONTINUOUS MAPPING
- **Paper**: arXiv 2025
- **GitHub**: Code availability unclear
- **Key Innovation**: **Dense continuous gene expression map** - aggregate into any spot size
- **Paradigm**: Implicit neural representation f(x,y,context)â†’expression
- **Why Critical**: Conceptually perfect for HD (dense outputs, sparse supervision)
- **Resolution**: Continuous (can aggregate to any bin size)
- **Priority**: **MEDIUM** - novel approach, code availability uncertain
- **Borrowed From**: NeRF / Coordinate MLPs (implicit neural representations)

### CarHE (2024)
- **Paper**: Published 2024
- **GitHub**: https://github.com/Jwzouchenlab/CarHE âœ…
- **Key Innovation**: **Contrastive Alignment for Visium HD**
- **Architecture**: CLIP-style contrastive learning + Transformer
- **Resolution**: **Explicitly designed for Visium HD 2Î¼m bins + Xenium (subcellular)**
- **Performance**: Predicts 17,000+ genes at 2Î¼m resolution
- **Why Critical**: First method explicitly validated on Visium HD 2Î¼m data
- **Priority**: **CRITICAL** - our exact use case (Visium HD 2Î¼m)
- **Borrowed From**: Web-scale image search (CLIP/OpenAI)

### DeepSpot2Cell (2024)
- **Paper**: Published 2024
- **GitHub**: https://github.com/ratschlab/DeepSpot2Cell âœ…
- **Key Innovation**: **Virtual Single-Cell Prediction via DeepSets/MIL**
- **Architecture**: Multiple Instance Learning + Pathology Foundation Models (UNI/Hoptimus0)
- **Resolution**: Virtual single-cell (~2Î¼m nuclear scale)
- **Paradigm**: Treats "spot" as bag of cells, deconvolves aggregate â†’ single-cell
- **Why Critical**: Super-resolution from coarse data (train on standard Visium, predict single-cell)
- **Priority**: **CRITICAL** - deconvolution approach novel
- **Borrowed From**: DeepSets / Multiple Instance Learning

### TissueNarrator (2024)
- **Paper**: Published 2024
- **GitHub**: Search pending
- **Key Innovation**: **LLM/Tokenization for Spatial Biology**
- **Architecture**: Treats tissue as "spatial sentences" (cells = words)
- **Paradigm**: Uses LLM architectures to predict based on "grammar" of cellular neighborhoods
- **Why Critical**: Most novel approach - applies NLP to spatial biology
- **Priority**: **HIGH** - extremely novel, may be overkill
- **Borrowed From**: Large Language Models (ChatGPT/BERT)

### Diff-ST (MICCAI 2024)
- **Paper**: MICCAI 2024
- **GitHub**: Search pending
- **Key Innovation**: **Diffusion for Image Super-Resolution â†’ ST**
- **Architecture**: Treats ST prediction as image super-resolution task
- **Why Critical**: Proven diffusion framework adapted for biology
- **Priority**: **HIGH** - diffusion approach established
- **Borrowed From**: Image restoration / Super-resolution

### STPath (2025) â­ FOUNDATION MODEL - GENERATIVE PARADIGM
- **Paper**: npj Digital Medicine 2025
- **GitHub**: Search pending (likely released)
- **Key Innovation**: **Generative Foundation Model for Spatial Transcriptomics**
- **Scale**: Pretrained on **~1,000 WSIs** paired with spatial transcriptomes across **17 organs**
  - Training corpus: **~4 million spatial spots** from combined public datasets
- **Architecture**:
  - Geometry-aware Transformer (attends across all spots in whole slide)
  - **Masked Gene Modeling**: Masks gene expression at some locations, predicts from image + context
  - Incorporates metadata (organ type, platform modality) as inputs
- **Resolution**: Can predict **~39,000 genes** at spot/cell level without fine-tuning
- **Paradigm**: Zero-shot "virtual sequencing" foundation model (like GPT for spatial biology)
- **Why Critical**:
  - First true foundation model for H&E â†’ RNA
  - Generalizes across tissues and sequencing platforms
  - Enables virtual sequencing for any archived pathology slide
- **Priority**: **CRITICAL** - paradigm-defining foundation model
- **Use Cases**:
  - Zero-shot gene prediction on new slides
  - Imputation of missing spatial spots
  - Survival prediction as transfer task
- **Borrowed From**: Foundation models (GPT-style masked modeling)
- **User Insight**: "A model that can predict transcriptomes for any tissue, at any resolution, without retraining"

---

## Tier 1: High Priority (Claims 2Î¼m/Subcellular + Code Available)

### GHIST (2025)
- **Paper**: Nature Methods 2025, Vol 22, pages 1900-1910
- **DOI**: https://doi.org/10.1038/s41592-025-02795-z
- **PMID**: 40954301
- **GitHub**: Not yet found (search pending)
- **Key Innovation**: Multitask deep learning for single-cell resolution prediction
- **Architecture**: Leverages cell nuclei morphology, cell-type info, neighborhood info, and gene expression jointly
- **Resolution**: Single-cell level (subcellular spatial transcriptomics)
- **Dataset**: Validated on public datasets + TCGA
- **Status**: Paper acquired âœ… (`papers/paywalled/GHIST_NatureMethods2025.pdf`)
- **Priority**: **CRITICAL** - claims 2Î¼m SOTA

### Img2ST-Net (2025, Huo Lab)
- **Paper**: Published 2025
- **PMID**: 41210922
- **Authors**: Huo lab (Vanderbilt)
- **Key Innovation**: Efficient high-resolution ST prediction via fully convolutional image-to-image learning
- **GitHub**: Search pending
- **Priority**: **CRITICAL** - from our own lab, likely tested on similar data

### sCellST (2024)
- **Paper**: bioRxiv 2024.11.07.622225v1
- **GitHub**: Search pending
- **Key Innovation**: Multiple Instance Learning for single-cell resolution
- **Architecture**: Uses cell morphology alone (single-cell images, not patches)
- **Resolution**: Single-cell level
- **Dataset**: PDAC (pancreatic ductal adenocarcinoma)
- **Status**: Preprint acquired âœ… (`papers/biorxiv/2024.11.07.622225v1.pdf`)
- **Priority**: **HIGH** - subcellular approach, novel MIL framework

### stImage (2025, Huo Lab)
- **Paper**: Published 2025
- **PMID**: 40905789
- **Authors**: Huo lab (Vanderbilt)
- **Key Innovation**: Versatile framework with customizable deep histology and location-informed integration
- **GitHub**: Search pending
- **Priority**: **HIGH** - from our lab, customizable framework

---

## Tier 1.5: Advanced Architectures (Novel Techniques from Other Fields)

### LUNA (2024)
- **Paper**: Search pending
- **GitHub**: Search pending
- **Key Innovation**: **Masked Language Modeling for Spatial Transcriptomics**
- **Architecture**: Spatial tokenization + Masked modeling
- **Technique**: Mask 20% of cells, predict from remaining 80% context
- **Why Critical**: Forces model to learn tissue organization rules
- **Priority**: **HIGH** - self-supervised learning approach
- **Borrowed From**: BERT/Masked Language Models (NLP)

### BLEEP (2024)
- **Paper**: Search pending
- **GitHub**: Search pending
- **Key Innovation**: **Shared Latent Spaces (H&E â†” RNA)**
- **Architecture**: Dual encoders + InfoNCE loss
- **Capability**: Zero-shot gene queries
- **Priority**: **MEDIUM** - contrastive learning variant
- **Borrowed From**: CLIP / Contrastive Learning

### HIPT (Hierarchical Image Pyramid Transformer)
- **Paper**: Search pending
- **GitHub**: Search pending
- **Key Innovation**: **Multi-scale hierarchical learning**
- **Architecture**: Zoom-out encoder (256Î¼m) + Zoom-in encoder (2Î¼m)
- **Why Critical**: Captures tissue architecture AND nuclear morphology
- **Priority**: **HIGH** - addresses context vs resolution trade-off
- **Borrowed From**: Satellite imaging / Gigapixel learning

### iStar (2024)
- **Paper**: Search pending
- **GitHub**: Search pending
- **Key Innovation**: **Hierarchical gigapixel learning**
- **Priority**: **MEDIUM** - hierarchical approach
- **Borrowed From**: Remote sensing

### ResSAT (2024)
- **Paper**: Search pending
- **GitHub**: https://github.com/StickTaTa/STGIN_main âœ… (verify)
- **Key Innovation**: **Graph Self-Supervised Residual Learning**
- **Architecture**: Spatial context + batch correction
- **Priority**: **MEDIUM** - GNN-based
- **Borrowed From**: Graph representation learning

### H&Enium (2024)
- **Paper**: Search pending
- **GitHub**: https://github.com/cbib/DeepSpot âœ… (verify branch)
- **Key Innovation**: **Foundation Model Alignment (H&E â†” scRNA-seq)**
- **Architecture**: Soft alignment target for biological noise tolerance
- **Resolution**: Cell-level/subcellular
- **Priority**: **MEDIUM** - alignment approach
- **Borrowed From**: Multi-modal contrastive learning

### SciSt (2024) â­ BIOLOGICAL PRIOR INJECTION
- **Paper**: Briefings in Bioinformatics 2024
- **GitHub**: Not publicly released, similar to sCellST approach
- **Key Innovation**: **Single-cell reference-informed framework**
- **Architecture**:
  - Step 1: Cell segmentation + counting (Hover-Net cell detector)
  - Step 2: Construct "Initial Expression (IE)" vector by weighting canonical gene profiles from scRNA atlas
  - Step 3: Dual encoders (ResNet34 + self-attention for image, MLP for IE)
  - Step 4: Fusion decoder refines gene prediction
- **Why Critical**: **Uses single-cell reference as biological prior** ("prompt engineering" for spatial biology)
- **Performance**: Outperformed HisToGene and THItoGene on HER2+ breast cancer (higher Pearson correlation)
- **Resolution**: Spot-level (55Î¼m), adaptable to subcellular
- **Priority**: **HIGH** - biological grounding significantly boosts accuracy
- **User Insight**: "By using single-cell reference prototypes as a 'prompt,' SciSt provides a biologically grounded prior"
- **Borrowed From**: Few-shot learning + biological knowledge injection

### DANet (2025) â­ DYNAMIC ALIGNMENT
- **Paper**: Bioinformatics 2025 (OUP)
- **GitHub**: Available on GitHub
- **Key Innovation**: **Dynamic Alignment Network with novel architectural components**
- **Architecture**:
  - **Densely connected CNN**: Captures intricate cellular details (preserves local info better than plain CNN)
  - **State-space model module**: Treats gene expression as sequence, models gene-gene dependencies
  - **Residual Kolmogorov-Arnold Network (RKAN)**: Learnable activation function for bimodal alignment
    - Dynamically adjusts how image features map to gene features during contrastive training
- **Performance**: ~20% gains in gene correlation metrics on public datasets
- **Datasets**: GSE240429 (human brain Visium), HER2+ breast cancer
- **Why Critical**: Novel activation learning (RKAN) for cross-modal alignment
- **Resolution**: Spot-level, adaptable
- **Priority**: **HIGH** - architectural innovation (RKAN) transferable to other methods
- **Borrowed From**: Kolmogorov-Arnold representation theorem + residual connections

### PRTS (2025) â­ ZERO-INFLATION HANDLING
- **Paper**: Science China Life Sciences 2025
- **GitHub**: Check PMC article for availability
- **Key Innovation**: **Two-head loss for sparse single-cell data**
- **Architecture**:
  - **Binary head**: Predicts whether gene is expressed at all (addresses dropout)
  - **Continuous head**: Predicts expression level if gene is present
- **Why Critical**: Explicitly tackles **zero-inflation** in high-resolution platforms (2Î¼m bins)
- **Problem Solved**: At 2Î¼m, most bins have zero counts for most genes (capture stochasticity, not biology)
- **Resolution**: Single-cell spatial transcriptomic maps
- **Priority**: **HIGH** - critical for handling 2Î¼m sparsity
- **User Insight**: "Addresses zero-inflation in high-resolution platforms by using a two-head loss"
- **Borrowed From**: Zero-inflated statistical models (ZINB, hurdle models)

### STMCL (2025) - CONTRASTIVE MULTI-SLICE
- **Paper**: Methods 2025
- **GitHub**: Search pending
- **Key Innovation**: **Inferring multi-slice spatial gene expression via contrastive learning**
- **Architecture**: Contrastive framework for aligning expression across serial sections
- **Why Critical**: Handles 3D reconstruction / serial section alignment
- **Resolution**: Multi-slice integration
- **Priority**: **MEDIUM** - useful for 3D spatial reconstruction (Month 5+)
- **Borrowed From**: Contrastive learning + cross-slice alignment

---

## Tier 2: High Priority (SOTA Methods, CVPR/Top Venues)

### TRIPLEX (2024)
- **Paper**: CVPR 2024
- **arXiv**: 2403.07592 (March 2024)
- **GitHub**: https://github.com/NEXGEM/TRIPLEX âœ…
- **Key Innovation**: Multi-resolution features (target spot, neighbor view, global view)
- **Architecture**: Fusion of 3 resolutions capturing cellular morphology â†’ local context â†’ global tissue organization
- **Metrics**: Outperforms SOTA in MSE, MAE, PCC
- **Dataset**: 3 public ST datasets + Visium (10X Genomics)
- **Priority**: **HIGH** - multi-scale approach relevant to 2Î¼m

### THItoGene (2024)
- **Paper**: Briefings in Bioinformatics 2024, Vol 25, Issue 1
- **DOI**: https://doi.org/10.1093/bib/bbad464
- **PMID**: 38145948
- **GitHub**: https://github.com/yrjia1015/THItoGene âœ…
- **Key Innovation**: Hybrid dynamic CNN + capsule networks
- **Architecture**: Adaptively senses molecular signals in histology
- **Dataset**: Human breast cancer + cutaneous squamous cell carcinoma
- **Priority**: **HIGH** - claims "improved Hist2ST", capsule networks novel

### Hist2ST (2022)
- **Paper**: Briefings in Bioinformatics 2022
- **GitHub**: https://github.com/biomed-AI/Hist2ST âœ…
- **Key Innovation**: CNN + Transformer + GNN hybrid
- **Architecture**:
  - CNN for 2D vision features
  - Transformer for global spatial relations
  - GNN for neighbor patch relations
  - ZINB distribution for gene expression
- **Dataset**: HER2+ breast cancer + cutaneous squamous cell carcinoma
- **Status**: **BASELINE** - current decoder in our 0.5699 SSIM system
- **Priority**: **CRITICAL** - our current baseline, understand internals

---

## Tier 3: Benchmark Studies (Critical Context)

### HEST-1K Benchmark (NeurIPS 2024)
- **Paper**: NeurIPS 2024 Spotlight
- **GitHub**: https://github.com/mahmoodlab/HEST âœ…
- **Key Innovation**: Comprehensive benchmark of 11 pathology foundation models
- **Tasks**: 9 tasks for gene expression prediction (50 HVGs)
- **Resolution**: 112Ã—112 Î¼m regions at 0.5 Î¼m/px
- **Organs**: 9 organs, 8 cancer types
- **Priority**: **CRITICAL** - establishes baseline for foundation model comparison
- **Action**: Apply for access (note in `USER_ACCESS_NEEDED.md`)

### Nature Communications Benchmark (Feb 2025)
- **Paper**: Nature Communications 2025
- **DOI**: https://doi.org/10.1038/s41467-025-56618-y
- **Key Innovation**: Reproduced 11 methods on 5 SRT datasets
- **Validation**: External validation on TCGA
- **Priority**: **HIGH** - comprehensive method comparison

### SpaRED Benchmark
- **GitHub**: https://github.com/BCV-Uniandes/SpaRED âœ…
- **Key Innovation**: Spatial transcriptomics completion for benchmarking
- **Priority**: **MEDIUM** - complementary benchmarking resource

---

## Tier 4: Integration/Transfer Methods

### Tangram (2021)
- **Paper**: Biancalani et al. 2021
- **GitHub**: https://github.com/broadinstitute/Tangram âœ…
- **Key Innovation**: Deep learning alignment of scRNA-seq to ST
- **Priority**: **MEDIUM** - label transfer, not direct H&E prediction

### SpaGE (2020)
- **Paper**: Abdelaal et al. 2020
- **GitHub**: https://github.com/tabdelaal/SpaGE âœ…
- **Key Innovation**: Spatial gene enhancement using scRNA-seq
- **Priority**: **MEDIUM** - enhancement, not direct prediction

### stLearn
- **GitHub**: https://github.com/BiomedicalMachineLearning/stlearn_interactive âœ…
- **Key Innovation**: H&E image integration for spot analysis
- **Priority**: **MEDIUM** - exploratory analysis, not prediction-focused

---

## Tier 5: Additional Methods (To Investigate)

### HistoSPACE (2024)
- **PMID**: 39521362
- **GitHub**: https://github.com/samrat-lab/HistoSPACE âœ…
- **Priority**: **MEDIUM** - recent method, needs investigation

### STMCL (2025)
- **Paper**: Multimodal contrastive learning framework
- **GitHub**: https://github.com/wenwenmin/STMCL âœ…
- **Key Innovation**: Integrates histology, gene expression, and location
- **Priority**: **MEDIUM** - contrastive learning approach novel

### HE2ST / DeepSpot
- **GitHub**: https://github.com/ratschlab/he2st âœ…
- **Key Innovation**: Leverages spatial context for enhanced prediction
- **Priority**: **MEDIUM** - spatial context methods

### hist2RNA
- **GitHub**: https://github.com/raktim-mondol/hist2RNA âœ…
- **Key Innovation**: Predicts gene expression from digital histology
- **Priority**: **LOW** - older method, lower priority

---

## Foundation Models (Encoders)

### Tested in Our Lab
1. **Prov-GigaPath** (current best, SSIM 0.5699 @ 2Î¼m, frozen)
2. **Virchow2** (frozen better than fine-tuned, -3.7% vs Prov-GigaPath)
3. **CONCH v1** (ViT-B/16, tested at 8Î¼m Ridge only, #5/7 encoders, r=0.467)

### Untested at 2Î¼m with Neural Decoder (Priority)
4. **UNI2-h** (ViT-H/14, 1536-dim, HF access acquired âœ…)
5. **CONCHv1.5** (ViT-L, larger than v1, **PRIORITY for Month 2**)
6. **H-optimus-1** (search needed)
7. **GigaPath** (non-Prov version, search needed)
8. **Phikon** (search needed)
9. **DenseNet** (baseline, likely tested)

---

## Cross-Disciplinary Inspiration (Month 1 Week 4)

### Super-Resolution Imaging
- **CARE** (Content-Aware Image Restoration)
- **CSBDeep** (framework for CARE)
- **Noise2Void** (self-supervised denoising)

### Weather Forecasting
- **GraphCast** (Google DeepMind, graph neural networks for global weather)
- **FourCastNet** (NVIDIA, Fourier neural operators)

### Protein Structure
- **AlphaFold 2/3** (attention mechanisms, MSA processing)
- **ESMFold** (language model for structure)

### Neural Rendering
- **NeRF** (Neural Radiance Fields)
- **Gaussian Splatting** (3D scene representation)

---

## Methods to Search (Pending)

Based on design document list, still need to find:
- [ ] HisToGene (different from THItoGene?)
- [ ] MERGE (hierarchical graph GNN)
- [ ] SpatialScope
- [ ] DeepST
- [ ] TESLA
- [ ] STAND
- [ ] Tissue-ViT
- [ ] ConvNeXt variants for pathology
- [ ] Spatial-GLUE
- [ ] stDiff (diffusion models for ST)
- [ ] Others from GitHub awesome lists

---

## Key Papers from Huo Lab (Vanderbilt)

1. **PMID:41210922** - Img2ST-Net (2025) â­
2. **PMID:40905789** - stImage (2025) â­
3. **PMID:41280008** - Computer Vision Methods for ST Survey (2025)
4. **PMID:40375953** - Spatial Pathomics Toolkit (2024)
5. **PMID:41323019** - PySpatial toolkit (2025)
6. **PMID:41256883** - Cell AI foundation models in kidney (2025)
7. **PMID:41286516** - Cell foundation models w/ human-in-the-loop (2025)
8. **PMID:41079265** - Assessment of Cell Nuclei AI Foundation Models (2025)

---

## Key Papers from Lau Lab (CRC Spatial Atlas)

1. **PMID:35794563** - CRC spatial atlas, CAF-TME crosstalk (2022) â­
2. **PMID:36669472** - Multiplexed 3D atlas of CRC (2023) â­
3. **PMID:38065082** - Molecular cartography in sporadic CRC (2023) â­
4. **PMID:34910928** - Pre-malignant programs in CRC polyps (2021)
5. **PMID:40026233** - Multiomic spatial atlas DMBT1 in dysplasia (2025)
6. **PMID:41042257** - Elemental imaging + ST in colon TME (2025)

---

## Key Papers from Sarkar Lab (ST Methods)

1. **PMID:39849132** - Mapping topography with interpretable DL (2025) â­
2. **PMID:37873258** - Same paper, preprint version (2023)

---

## Action Items

### Immediate (Week 1)
- [x] Complete initial method inventory
- [ ] Clone Tier 1 GitHub repos (TRIPLEX, THItoGene, Hist2ST)
- [ ] Acquire papers via PubMed/bioRxiv APIs
- [ ] Update `CODE_ARCHAEOLOGY.md` with initial findings
- [ ] Search for remaining methods in "Pending" list

### Week 2
- [ ] Deep extraction of GHIST architecture (paper acquired)
- [ ] Deep extraction of TRIPLEX architecture
- [ ] Deep extraction of THItoGene architecture
- [ ] Deep extraction of sCellST architecture
- [ ] Test CONCHv1.5 empirically at 2Î¼m

### Week 3
- [ ] Identify common architectural patterns
- [ ] Statistical analysis: performance vs complexity
- [ ] Document "critical ingredients" for 2Î¼m success

### Week 4
- [ ] Mine cross-disciplinary literature
- [ ] Generate 10-15 novel hypothesis candidates

---

## Key Architectural Insights (User-Provided SOTA Analysis)

### Paradigm Shift: Regression â†’ Generative
- **Old Approach**: CNNs with regression heads â†’ predict mean expression (blurry, misses rare cells)
- **New Approach**: Diffusion models (Stem, Diff-ST) â†’ learn distribution of expressions
- **Impact**: Handles "one-to-many" biology (same morphology â†’ multiple possible states)

### Critical Techniques Borrowed from Other Fields

1. **From Generative AI**: Latent Diffusion Models (Stable Diffusion â†’ Stem, Diff-ST)
   - Generate sharp, multimodal distributions
   - Predict Cell Type A OR B (not averaged muddy signal)

2. **From NLP**: Tokenization + Masked Modeling (BERT â†’ TissueNarrator, LUNA)
   - Cells = words, tissue = sentences
   - Mask 20% of cells, predict from 80% context
   - Learns "tissue grammar"

3. **From Web-Scale Search**: Contrastive Learning (CLIP â†’ CarHE, BLEEP, H&Enium)
   - Shared latent spaces (H&E â†” RNA)
   - InfoNCE loss
   - Enables zero-shot gene queries

4. **From Satellite Imaging**: Hierarchical Gigapixel Learning (HIPT, iStar)
   - Zoom-out (256Î¼m tissue architecture) + Zoom-in (2Î¼m nuclear morphology)
   - Addresses context vs resolution trade-off

### The "Winning Frankenstein Architecture" (User Recommendation)

**Do NOT use simple CNN (ResNet/EfficientNet) - that approach has plateaued.**

**Recommended Stack**:
1. **Encoder**: Pathology Foundation Model (UNI, CONCH, Virchow) - do NOT train from scratch
2. **Context**: Graph Neural Network OR Transformer to aggregate neighbor features (spatial context)
3. **Prediction Head**: Diffusion Head (NOT regression head) to preserve variance + biological noise

**Critical for 2Î¼m**:
- **Input**: Large context patch (256Ã—256 px, ~100+ Î¼m) - NOT just 2Î¼m crop
- **Architecture**: Vision Transformer OR Hierarchical CNN
- **Output**: Dense prediction map (pixel-wise or 2Î¼m bin-wise) where center pixel inferred from surrounding context

---

## Tier 6: Cross-Disciplinary Techniques (Mathematical Isomorphisms)

**Source**: Project Aether strategic analysis - identifying mathematical parallels from remote sensing, medical imaging, and computer vision

### Remote Sensing: Hyperspectral Pansharpening

**The Isomorphism**:
- **Remote Sensing**: Panchromatic image (high spatial, low spectral) + Hyperspectral image (low spatial, high spectral) â†’ Fused high-res hyperspectral
- **Our Domain**: H&E (high spatial, 3 channels) + Visium (low spatial, 20K genes) â†’ Fused high-res gene expression

#### HyperPNN (Hyperspectral Pansharpening Neural Network)
- **Paper**: IEEE Transactions on Geoscience and Remote Sensing
- **GitHub**: Search "HyperPNN" + author names from papers
- **Key Innovation**: Spectral predictive branch - predicts high-level spectral ratios from high-res image
- **Adaptation**: Predict "transcriptomic residuals" (how cell deviates from neighborhood mean)
- **Priority**: MEDIUM - architectural inspiration for attention mechanisms
- **Status**: Conceptual transfer, not direct code reuse

#### HSpeNet (Hyperspectral Network)
- **Paper**: Remote sensing literature
- **GitHub**: Search "HSpeNet pansharpening"
- **Key Innovation**: **Dual-Attention Fusion Block (DAFB)**
  - Spatial Attention: Identifies "where" (nuclei vs stroma)
  - Spectral Attention: Identifies "which genes" correlate with textures
- **Adaptation**: Replace Cross-Attention in Stem with DAFB layers
  - H&E embedding = "PAN" input
  - Gene embeddings = "HS" input
  - Enforces: Gene variance must be grounded in morphological variance
- **Priority**: HIGH - direct architectural component for "Clean Frankenstein"
- **User Insight**: "Spatial-Spectral Attention to attend to spatial textures and correlate them with spectral bands"

### Medical Imaging: Implicit Neural Representations (INRs)

#### STINR (Spatial Transcriptomics via Implicit Neural Representation)
- **Paper**: "Deciphering Spatial Transcriptomics via Implicit Neural Representation"
- **GitHub**: Search for STINR implementations
- **Key Innovation**: Models gene expression as continuous function f(x,y) â†’ gene vector
  - Parametrized by MLP (Multilayer Perceptron)
  - Provides "infinite resolution" - query at any (x,y) coordinate
- **Adaptation**: **Image-Guided INR** - condition MLP on both coordinates AND image features I(x,y)
  - Similar to Local Implicit Image Functions (LIIF) in computer vision
  - Use as decoder: Encoder extracts latent grid â†’ INR queries at ENACT cell centroids
- **Priority**: HIGH - solves spatial discontinuity (point cloud of cells vs fixed pixel grid)
- **Benefits**:
  - Decouples image resolution from prediction resolution
  - Train on Visium HD, deploy for single-cell prediction
  - 3D reconstruction: Stack sections, query continuous volume

#### SUICA (Spatial Unsupervised Image-based Clustering and Analysis)
- **Paper**: Related to STINR, verify exact method
- **Key Innovation**: INR for spatial clustering
- **Priority**: LOW - STINR more relevant for our use case

#### LIIF (Local Implicit Image Functions)
- **Paper**: Computer vision (CVPR 2021)
- **GitHub**: https://github.com/yinboc/liif
- **Key Innovation**: Learn continuous image representation, super-resolution at arbitrary scales
- **Adaptation**: Template for image-guided INR decoder in our architecture
- **Priority**: MEDIUM - reference implementation for INR architecture

#### JIIF (Joint Implicit Image Function)
- **Paper**: MRI super-resolution literature
- **Key Innovation**: Continuous 3D volume representation, interpolate between slices
- **Adaptation**: Future 3D reconstruction (stack H&E sections, predict continuous ST volume)
- **Priority**: LOW (Month 5+) - for 3D spatial reconstruction

### Computer Vision: Continuous Representations

#### NeRF-style Approaches
- **Concept**: Neural Radiance Fields - continuous 3D scene representation
- **Adaptation**: PixNet appears to use similar paradigm (dense continuous gene map)
- **Priority**: LOW - PixNet already captures this approach in Tier 0

---

---

## Tier 8: Datasets and Benchmarks (Critical Infrastructure)

### HEST-1k â­ PRIMARY BENCHMARK
- **Paper**: arXiv 2406.16192
- **HuggingFace**: https://hf.co/papers/2406.16192
- **What**: Multimodal dataset integrating ST + histology across tissues
- **Why Critical**: Gold standard benchmark for cross-tissue generalization
- **Scale**: 1,000+ ST-WSI pairs, 11 foundation model benchmarks
- **Tasks**: 50 HVG prediction at 112Ã—112 Î¼m @ 0.5 Î¼m/px
- **Coverage**: 9 organs, 8 cancer types
- **Use Case**: Month 5 external validation (cross-tissue generalization)
- **Status**: USER_ACCESS_NEEDED.md (ðŸŸ¡ MEDIUM priority)
- **Priority**: **CRITICAL** for proving generalization beyond CRC

### STimage-1K4M - SUB-TILE SCALE DATASET
- **Paper**: arXiv 2406.06393
- **HuggingFace**: https://hf.co/papers/2406.06393
- **What**: Histopathology imageâ€“gene expression at sub-tile scale
- **Why Relevant**: Dense supervision paradigm (vs sparse spot-level)
- **Scale**: 1K images, 4M sub-tiles
- **Use Case**: Understanding fine-grained supervision strategies
- **Priority**: MEDIUM - conceptual inspiration for 2Î¼m dense prediction

### HESCAPE â­ BATCH EFFECTS BENCHMARK
- **Paper**: arXiv 2508.01490
- **HuggingFace**: https://hf.co/papers/2508.01490
- **What**: Large-scale cross-modal learning benchmark
- **Why CRITICAL**: **Explicitly highlights batch effects as central obstacle**
- **Insight**: Most methods fail across sites/scanners/stains
- **Use Case**: Batch correction strategies, eval protocol design
- **Priority**: **HIGH** - batch effects will kill generalization

---

## Tier 9: Foundation Models and Backbones (Extended)

### Threads â­ MOLECULAR-DRIVEN FOUNDATION MODEL
- **Paper**: arXiv 2501.16652
- **HuggingFace**: https://hf.co/papers/2501.16652
- **What**: Molecular-driven slide foundation model
- **Training**: Multimodal (genomics + transcriptomics signals)
- **Why Different**: Explicitly trained with molecular supervision (not just images)
- **Use Case**: May provide better gene-aware features than pure vision FMs
- **Priority**: **HIGH** - molecular supervision aligns with our task
- **Status**: Check if weights available

### mSTAR - MULTIMODAL KNOWLEDGE-ENHANCED FM
- **Paper**: arXiv 2407.15362
- **HuggingFace**: https://hf.co/papers/2407.15362
- **What**: Whole-slide foundation model including gene expression
- **Training**: Multi-task across 100+ pathology tasks
- **Why Relevant**: Already seen gene expression during training
- **Use Case**: Transfer learning from gene-aware pretraining
- **Priority**: MEDIUM-HIGH

### PathOrchestra - 100+ TASK FM
- **Paper**: arXiv 2503.24345
- **HuggingFace**: https://hf.co/papers/2503.24345
- **What**: Foundation model trained on 100+ pathology tasks
- **Why Relevant**: Transfer learning breadth, eval protocol ideas
- **Use Case**: Understanding what tasks help ST prediction
- **Priority**: MEDIUM

### PAST â­ PATHOLOGY + scRNA FOUNDATION MODEL
- **Paper**: arXiv 2507.06418
- **HuggingFace**: https://hf.co/papers/2507.06418
- **What**: Pathology + single-cell transcriptomes foundation model
- **Capabilities**: Gene expression prediction + virtual staining
- **Why Critical**: Directly trained for our task (H&E â†’ genes)
- **Priority**: **CRITICAL** - may be best pretrained backbone
- **Status**: Check weights availability

---

## Tier 10: Direct Gene Expression Prediction Methods

### hist2RNA â­ BASELINE + PITFALLS
- **Paper**: arXiv 2304.04507
- **HuggingFace**: https://hf.co/papers/2304.04507
- **What**: Efficient architecture predicting gene expression from H&E
- **Why Critical**: Documents common pitfalls and baseline approach
- **Architecture**: CNN-based with spatial aggregation
- **Use Case**: Baseline comparison, learn from mistakes
- **Priority**: **HIGH** - lessons learned document

### Gene-DML - DUAL-PATHWAY DISCRIMINATION
- **Paper**: arXiv 2507.14670
- **HuggingFace**: https://hf.co/papers/2507.14670
- **What**: Dual-pathway multi-level discrimination
- **Architecture**: Aligns morphology â†” transcript representations
- **Innovation**: Multi-level feature alignment (not just final layer)
- **Priority**: HIGH - architectural idea for Clean Frankenstein

### SToFM - SPATIAL TRANSCRIPTOMICS FM
- **Paper**: arXiv 2507.11588
- **HuggingFace**: https://hf.co/papers/2507.11588
- **What**: Foundation model framing for spatial transcriptomics
- **Innovation**: Multi-scale extraction at different resolutions
- **Use Case**: Scale-handling strategies for 2Î¼m
- **Priority**: MEDIUM-HIGH

---

## Tier 11: Cross-Modal Alignment Methods

### MIRROR â­ MODALITY ALIGNMENT + RETENTION
- **Paper**: arXiv 2503.00374
- **HuggingFace**: https://hf.co/papers/2503.00374
- **What**: Multi-modal pathological self-supervised learning
- **Key Insight**: **Don't destroy modality-specific signal during alignment**
- **Problem Solved**: Naive contrastive learning collapses unique info
- **Architecture**: Balanced alignment + retention objectives
- **Priority**: **HIGH** - critical for cross-modal fusion
- **User Insight**: "Modality alignment + retention (don't destroy modality-specific signal)"

---

## Tier 12: MIL and WSI Aggregation

### Do MIL Models Transfer? â­ TRANSFER LEARNING STUDY
- **Paper**: arXiv 2506.09022
- **HuggingFace**: https://hf.co/papers/2506.09022
- **Question**: Can I reuse pretrained MIL aggregators across organs/tasks?
- **Answer**: Provides empirical evidence on MIL transfer
- **Use Case**: Deciding whether to pretrain MIL on other data
- **Priority**: **HIGH** - informs whether to use DeepSpot2Cell aggregator directly

### MambaMIL - LONG-SEQUENCE MIL
- **Paper**: arXiv 2403.06800
- **HuggingFace**: https://hf.co/papers/2403.06800
- **What**: State-space models for long-sequence WSI MIL
- **Innovation**: Mamba architecture (linear complexity vs quadratic Transformer)
- **Use Case**: If modeling lots of 2Î¼m patches/spots
- **Priority**: MEDIUM - efficiency gain for large slides

---

## Tier 13: Generative Models (Data Augmentation)

### PixCell - DIFFUSION FOR HISTOPATHOLOGY
- **Paper**: arXiv 2506.05127
- **HuggingFace**: https://hf.co/papers/2506.05127
- **What**: Diffusion-based generative foundation model for histopath
- **Use Case**: Synthetic diversity, augmentation if data is bottleneck
- **Priority**: LOW (we have 3 patients, synthetic won't help much)
- **Future**: Useful for rare cell type augmentation

---

## Tier 14: Robustness and Generalization Methods (Outside Disciplines)

**Source**: Cross-disciplinary intelligence - domain adaptation, SSL, long-context, equivariance, uncertainty

### A) Domain Adaptation and Test-Time Adaptation

#### Test-Time Batch Statistics Calibration â­ CRITICAL FOR BATCH EFFECTS
- **Paper**: arXiv 2110.04065
- **HuggingFace**: https://hf.co/papers/2110.04065
- **What**: Adapt batch normalization stats at inference to handle covariate shift
- **Why Critical**: HESCAPE shows most methods fail across sites/scanners/stains
- **Implementation**: Freeze encoder+head, recalculate BN stats per slide/batch
- **Cost**: Cheap (no retraining), often strong
- **Priority**: **CRITICAL** - addresses batch effects (our #1 generalization risk)
- **Experiment**: TTA BN calibration per slide, measure cross-site performance recovery
- **Timeline**: Month 5 Week 2 (external validation on HEST-1k)

#### Source-Free Domain Adaptation
- **Paper**: arXiv 2206.08009 (Balancing Discriminability and Transferability)
- **HuggingFace**: https://hf.co/papers/2206.08009
- **What**: Adapt without source data (privacy-relevant, can't pool slides)
- **Priority**: MEDIUM - useful if HEST-1k inaccessible or privacy constraints

### B) Optimal Transport Alignment (ALREADY INTEGRATED âœ…)

- âœ… **We have**: POT library, Wasserstein distance in SpatialEvaluator
- âœ… **Using**: OT as evaluation metric + potential loss function

**Additional OT Methods (if needed)**:

#### InfoOT - Information Maximizing OT
- **Paper**: arXiv 2210.03164
- **HuggingFace**: https://hf.co/papers/2210.03164
- **What**: OT + mutual information for better alignment
- **Use Case**: If naive OT alignment insufficient
- **Priority**: LOW (POT library sufficient for now)

#### Unbalanced CO-Optimal Transport
- **Paper**: arXiv 2205.14923
- **HuggingFace**: https://hf.co/papers/2205.14923
- **What**: Robust OT for heterogeneous/noisy measurements (batch effects)
- **Priority**: MEDIUM - if batch effects dominate

#### Graph Optimal Transport
- **Paper**: arXiv 2006.14744
- **HuggingFace**: https://hf.co/papers/2006.14744
- **What**: Align graph structures (neighborhood relations)
- **Priority**: LOW (we use spatial graphs, but standard OT sufficient)

### C) Self-Supervised Pretraining (Leverage Unlabeled WSIs)

#### MAE - Masked Autoencoders â­ HIGH PRIORITY
- **Paper**: arXiv 2111.06377
- **HuggingFace**: https://hf.co/papers/2111.06377
- **What**: Masked image modeling (mask patches, reconstruct)
- **Why Relevant**: We have tons of unlabeled H&E, SSL improves representation quality
- **Implementation**: Pretrain patch encoder on unlabeled WSIs, fine-tune for ST
- **Expected Gain**: Improves both in-domain accuracy and out-of-domain robustness
- **Priority**: **HIGH** - strong empirical track record
- **Timeline**: Month 2 Week 4 or Month 3 Week 1 (after baseline methods tested)

#### MR-MAE - Mimic before Reconstruct
- **Paper**: arXiv 2303.05475
- **HuggingFace**: https://hf.co/papers/2303.05475
- **What**: Improved MAE variant (mimic before reconstruct)
- **Priority**: MEDIUM - if MAE chosen, try this variant

#### BYOL - Bootstrap Your Own Latent
- **Paper**: arXiv 2006.07733
- **HuggingFace**: https://hf.co/papers/2006.07733
- **What**: Non-contrastive SSL (stable, no negatives)
- **Priority**: MEDIUM - alternative to MAE

#### Barlow Twins
- **Paper**: arXiv 2103.03230
- **HuggingFace**: https://hf.co/papers/2103.03230
- **What**: Redundancy-reduction SSL (no negatives)
- **Priority**: MEDIUM - alternative to MAE

#### VICReg - Variance-Invariance-Covariance Regularization
- **Paper**: arXiv 2105.04906
- **HuggingFace**: https://hf.co/papers/2105.04906
- **What**: Redundancy-control SSL
- **Priority**: MEDIUM - alternative to MAE
- **Note**: User recommends "MAE *or* VICReg" as top choices

### D) Long-Context / Efficient Attention

#### Longformer â­ CONCEPTUAL TEMPLATE
- **Paper**: arXiv 2004.05150
- **HuggingFace**: https://hf.co/papers/2004.05150
- **What**: Linear-ish attention for long documents
- **Why Relevant**: WSI = long sequence problem (100K-1M patches)
- **Use Case**: Include 5-20Ã— more tissue context per slide/region
- **Priority**: **HIGH** - unlocks whole-slide context
- **Timeline**: Month 4 Week 1 (novel architecture design)

#### Ring Attention with Blockwise Transformers
- **Paper**: arXiv 2310.01889
- **HuggingFace**: https://hf.co/papers/2310.01889
- **What**: Distributed long-context attention (engineering unlock)
- **Priority**: HIGH - enables scaling to full WSI context

#### Mega - Moving Average Equipped Gated Attention
- **Paper**: arXiv 2209.10655
- **HuggingFace**: https://hf.co/papers/2209.10655
- **What**: Alternative efficient attention mechanism
- **Priority**: MEDIUM - if Longformer/Ring Attention insufficient

### E) Equivariance (Rotation/Shift Robustness)

#### Equivariant Transformer Networks
- **Paper**: arXiv 1901.11399
- **HuggingFace**: https://hf.co/papers/1901.11399
- **What**: Baseline equivariant architecture concept
- **Why Relevant**: Histology has rotation/shift symmetries
- **Priority**: MEDIUM - improves sample efficiency, reduces augmentation need

#### Shift Equivariance in Vision Transformers
- **Paper**: arXiv 2306.07470
- **HuggingFace**: https://hf.co/papers/2306.07470
- **What**: Make ViTs less brittle to patch grid shifts (tiling artifacts)
- **Priority**: MEDIUM-HIGH - relevant to Visium HD grid alignment
- **Use Case**: If model sensitive to rotation/tiling

#### Equivariant Contrastive Learning
- **Paper**: arXiv 2111.00899
- **HuggingFace**: https://hf.co/papers/2111.00899
- **What**: SSL that learns what should be equivariant vs invariant
- **Priority**: MEDIUM - combines SSL + equivariance

### F) Uncertainty and Calibration â­ CRITICAL FOR DEPLOYMENT

#### CRUDE - Calibrated Regression Under Distribution Shift
- **Paper**: arXiv 2005.12496
- **HuggingFace**: https://hf.co/papers/2005.12496
- **What**: Simple regression uncertainty calibration
- **Why Critical**: Gene expression prediction is high-stakes under shift
- **Output**: Prediction intervals + confidence scores
- **Priority**: **CRITICAL** - makes model operational (not just leaderboard toy)
- **Timeline**: Month 5 Week 3 (after optimization, before publication)

#### Density-Aware Calibration
- **Paper**: arXiv 2302.05118
- **HuggingFace**: https://hf.co/papers/2302.05118
- **What**: Robust calibration under domain shift
- **Priority**: HIGH - complementary to TTA

#### Regression Calibration Survey
- **Paper**: arXiv 2306.02738
- **HuggingFace**: https://hf.co/papers/2306.02738
- **What**: Empirical map of what works in regression calibration
- **Priority**: MEDIUM - reference for choosing calibration method

---

## Tier 14 Summary: Recommended Integration Strategy

### Clean Strategy (Conservative, High ROI)
1. **MAE or VICReg** (Month 3): Pretrain patch encoder on unlabeled WSIs
2. **TTA BN Calibration** (Month 5): Add test-time adaptation for batch effects
3. **CRUDE Calibration** (Month 5): Produce prediction intervals for operational use

### Aggressive Strategy (Win on Generalization)
1. **OT-based alignment** (Month 4): Cross-cohort/modality alignment (InfoOT, Unbalanced COOT)
2. **Long-context attention** (Month 4): Longformer/Ring Attention for whole-slide context
3. **Calibration** (Month 5): Uncertainty quantification (CRUDE, Density-Aware)

### Critical Gap Filled
- **Batch Effects**: TTA BN Calibration (Month 5) addresses HESCAPE warning
- **Deployment Readiness**: CRUDE calibration (Month 5) makes predictions usable

---

## Tier 7: Evaluation Frameworks and Tools

### scIB-E (Single-cell Integration Benchmarking - Extended)
- **Paper**: Nature Methods (original scIB), verify scIB-E extension
- **GitHub**: https://github.com/theislab/scib (search for extended metrics)
- **Purpose**: **Biological Conservation Metrics**
  - Beyond correlation - does model preserve cell types and states?
- **Metrics**:
  - **Adjusted Rand Index (ARI)**: Cluster agreement with ground truth
  - **Normalized Mutual Information (NMI)**: Information shared between clusterings
  - **Local Inverse Simpson's Index (LISI)**: Local diversity/mixing
  - **Silhouette Score**: Cluster separation on cell types
- **Implementation**: Use `scib-metrics` Python library
- **Priority**: **CRITICAL for Day 0-1** - defines evaluation harness
- **User Insight**: "Ultimate test is whether predicted expression clusters correctly"

### POT (Python Optimal Transport)
- **GitHub**: https://github.com/PythonOT/POT
- **Purpose**: **Wasserstein Distance / Earth Mover's Distance**
- **Why Critical**:
  - PCC/SSIM punish spatial shifts harshly (B-cell 10Âµm away = complete mismatch)
  - Wasserstein recognizes nearby cells, assesses geometrically appropriate penalty
- **Use Cases**:
  - Loss function: Sinkhorn Divergence for training
  - Evaluation: Wasserstein distance between predicted/true distributions
- **Implementation**: `ot.sinkhorn()`, `ot.emd()`
- **Priority**: **CRITICAL for Day 0-1** - core evaluation metric
- **User Insight**: "OT measures 'effort' to transform predicted distribution into ground truth"

### SpatialQC (Spatial Fidelity Metrics)
- **Purpose**: Spatial pattern validation beyond per-pixel metrics
- **Metrics**:
  - Spatially Variable Gene (SVG) recovery
  - Spatial autocorrelation (Moran's I)
  - Cell-type spatial distribution
- **Priority**: MEDIUM - complementary to scIB-E

---

## Mathematical Formulations (from Aether Report)

### DeepSet (MIL Architecture)
```
f(X) = Ï(Î£_{xâˆˆX} Ï†(x))
```
- X = set of cells in region
- Ï† = encoder network (per cell)
- Ï = decoder network (per spot)
- Summation ensures permutation invariance

### Diffusion Model (Stem)
- Problem: p(y|x) is multimodal (same morphology â†’ multiple states)
- Regression: minimizes ||Å· - y||Â² â†’ converges to E[y|x] (conditional mean = blur)
- Diffusion: learns distribution p(y|x) itself, samples from manifold of valid states

### Optimal Transport Loss
- Wasserstein distance W(P,Q) = "effort" to transform distribution P into Q
- Sinkhorn Divergence: differentiable approximation for training
- Better than MSE for sparse, discrete count data

---

### Optimized Execution Order (User-Recommended)

**"If you told me 'win within 8-12 weeks,' I'd do:"**

**Step 0 (Days 0-1): Lock the Eval Definition** âš ï¸ CRITICAL
- **Decide**: Raw 2Î¼m bins vs 8Î¼m bins vs cell-level?
- **Metrics**: Gene-wise correlation + SVG recovery + cell-type recovery (NOT just SSIM)
- **Why**: Prevent trivial smoothing, reward biological signal
- **Reference**: GHIST shows cell-type accuracy style evaluation

**Step 1 (Days 1-2): Steal ENACT's Binâ†’Cell Machinery** â­ THE MISSING PIECE
- **Goal**: Produce cell-by-gene matrices from Visium HD + segmentation
- **Action**: Clone https://github.com/Sanofi-Public/enact-pipeline
- **Extract**: Cell segmentation, bin-to-cell assignment, AnnData output
- **Why**: "Without this, you're not truly working at 2Î¼m"

**Step 2 (Days 2-3): Get a Generative Baseline Running**
- **Option A (fast proof)**: Run **Stem** (clean repo, HEST integration)
- **Option B (slide-level structure)**: Run **STFlow** (whole-slide joint modeling)
- **Why**: Generative > regression for sparse/zero-inflated 2Î¼m bins

**Step 3 (Days 3-4): Extract MIL/DeepSets Aggregator**
- **Source**: DeepSpot2Cell
- **Goal**: "Bag of subspots/cells â†’ spot" logic as drop-in module
- **Why**: Handles partial cells/bins correctly

**Step 4 (Days 4-5): Decide Count Handling**
- **Problem**: MSE plateaus on HD sparsity (DeepSpot2Cell uses MSE = easy to beat)
- **Option A**: Swap to **GenAR** (discrete counts/tokens)
- **Option B**: Keep Stem diffusion (continuous but generative)
- **Option C**: Report both

**The "Clean Frankenstein" (High Probability of Working)**:
```
PFM Encoder â†’ Multiscale Context â†’ MIL Aggregator â†’ Generative Head
     â†“              â†“                    â†“                  â†“
   UNI/Virchow   HIPT/Local        DeepSpot2Cell      Stem/STFlow/GenAR
```

**The "Aggressive Frankenstein" (Highest Upside, Highest Risk)**:
1. **Contrastive pretrain** (BLEEP/H&Enium/CarHE) â†’ stable H&Eâ†”RNA latent
2. **Generative finetune** (diffusion/flow/AR counts) conditioned on latent
3. Optional: Retrieval of RNA prototypes (nearest-neighbor gene vectors) during decoding

---

### Novel Hypotheses Generated

**From Initial SOTA Analysis**:
- H_diff_001: Replace our MSE loss with conditional diffusion head
- H_contrast_001: Use contrastive learning (CLIP-style) instead of supervised regression
- H_hier_001: Hierarchical encoders (tissue + cellular scales)
- H_mil_001: Treat Visium HD 2Î¼m bins as bags of sub-cellular features
- H_token_001: Spatial tokenization + masked modeling for self-supervised pretraining

**From Updated Analysis**:
- H_enact_001: ENACT-style cell-level ground truth vs raw bin-level
- H_flow_001: Flow matching (STFlow) vs diffusion (Stem) for slide-level structure
- H_discrete_001: Discrete count generation (GenAR) vs continuous (Stem/MSE)
- H_franken_001: Full Frankenstein (PFMâ†’HIPTâ†’MILâ†’Diffusion)
- H_2stage_001: Two-stage (contrastive pretrain â†’ generative finetune)

---

### Predictable Failure Modes (Watch For These)

1. **Stain/Batch Artifact Leakage**: Model "wins" metrics by learning slide-level artifacts
   - **Prevention**: Slide-level train/test splits, cross-stain validation
2. **Registration Noise Dominates**: Model learns blur, not biology
   - **Prevention**: ENACT jitter stress tests, alignment QC
3. **Degenerate Loss (All Zeros)**: Raw 2Î¼m sparsity â†’ loss collapses
   - **Prevention**: Generative heads (diffusion/flow/discrete counts), NOT MSE
4. **Trivial Smoothing**: High SSIM from Gaussian blur
   - **Prevention**: SVG recovery, cell-type accuracy, pathway alignment metrics

---

## Notes

- **Polymax database**: synthesis_run_id = 77 (initialized for this project)
- **Memory graph**: 8 entities created with baseline findings
- **GitHub access**: Some repos require authentication (use `gh` CLI if needed)
- **HEST-1K**: Requires application for access - add to `USER_ACCESS_NEEDED.md`
- **Papers acquired**: GHIST (paywalled), sCellST (bioRxiv), 1 arXiv preprint
- **Prioritization rule**: Methods claiming 2Î¼m/subcellular + code > SOTA methods > benchmarks > baselines

---

## Meta-Resources (Stay Comprehensive Without Drowning)

### Curated Lists
1. **Awesome Vision-driven Models for Spatial Omics**
   - GitHub: https://github.com/hrlblab/computer_vision_spatial_omics
   - Living list of ST prediction methods
   - Includes methodological categorization

2. **HEtoSGEBench** (Benchmarking Pipeline)
   - GitHub: https://github.com/SydneyBioX/HEtoSGEBench
   - Forces honest eval hygiene
   - Useful for spot-based prediction pipelines

### Foundation Model Hubs
- **HuggingFace Mahmood Lab**: UNI, UNI2-h, CONCH, CONCHv1.5, FEATHER models
- **HuggingFace Bioptimus**: H-optimus-0, H0-mini
- **Paige AI**: Virchow, Virchow2 (Azure marketplace)

### Datasets
- **HEST-1K** (NeurIPS 2024): 1000+ paired ST + WSI, 11 FM benchmark
- **10X Visium HD Public**: Human Colon Cancer (https://github.com/10XGenomics/HumanColonCancer_VisiumHD)
- **Ken Lau CRC Atlas**: 6 papers, potential validation cohort

---

**Last Updated**: 2025-12-26 (Post-user intelligence integration)
**Next Update**: After Week 2 code archaeology + eval definition locked
**Total Methods**: 45+ (Tier -1 to Tier 5)
**Execution-Ready**: YES âœ…
